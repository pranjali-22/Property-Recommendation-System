{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b12164e",
   "metadata": {},
   "source": [
    "### Property Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3c9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbde6c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (88, 1)\n"
     ]
    }
   ],
   "source": [
    "with open('appraisals_dataset.json', 'r') as f:\n",
    "    appraisals_dataset = pd.read_json(f)\n",
    "print(\"Data shape:\", appraisals_dataset.shape)\n",
    "\n",
    "df = pd.json_normalize(appraisals_dataset['appraisals'].tolist())\n",
    "df.to_csv('appraisals.csv', index=False)\n",
    "df = pd.read_csv('appraisals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f1782a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (70, 38)\n",
      "Testing set shape: (18, 38)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Testing set shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a750b",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e92293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "import ast\n",
    "\n",
    "properties = train_df[['orderID', 'properties']]\n",
    "\n",
    "records = []\n",
    "for _, row in properties.iterrows():\n",
    "    orderID = row['orderID']\n",
    "    prop_list = row['properties']\n",
    "    prop_list = ast.literal_eval(prop_list)\n",
    "    if isinstance(prop_list, str):\n",
    "        try:\n",
    "            prop_list = json.loads(prop_list.replace(\"'\", '\"'))\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    for prop in prop_list:\n",
    "        prop_record = {\n",
    "            \"orderID\": orderID,\n",
    "            \"id\":prop.get(\"id\", None),\n",
    "            \"address\": prop.get(\"address\", None),\n",
    "            \"bedrooms\": prop.get(\"bedrooms\", None),\n",
    "            \"gla\": prop.get(\"gla\", None),\n",
    "            \"city\": prop.get(\"city\", None),\n",
    "            \"province\": prop.get(\"province\", None),\n",
    "            \"postal_code\": prop.get(\"postal_code\", None),\n",
    "            \"property_sub_type\": prop.get(\"property_sub_type\", None),\n",
    "            \"structure_type\": prop.get(\"structure_type\", None),\n",
    "            \"style\": prop.get(\"style\", None),\n",
    "            \"levels\": prop.get(\"levels\", None),\n",
    "            \"room_count\": prop.get(\"room_count\", None),\n",
    "            \"full_baths\": prop.get(\"full_baths\", None),\n",
    "            \"half_baths\": prop.get(\"half_baths\", None),\n",
    "            \"lot_size_sf\": prop.get(\"lot_size_sf\", None),\n",
    "            \"year_built\": prop.get(\"year_built\", None),\n",
    "            \"roof\": prop.get(\"roof\", None),\n",
    "            \"basement\": prop.get(\"basement\", None),\n",
    "            \"cooling\": prop.get(\"cooling\", None),\n",
    "            \"heating\": prop.get(\"heating\", None),\n",
    "        }\n",
    "        records.append(prop_record)\n",
    "\n",
    "properties_df = pd.DataFrame(records)\n",
    "properties_df = properties_df.rename(columns={\n",
    "    col: f\"prop.{col}\" for col in properties_df.columns if col != \"orderID\"\n",
    "})\n",
    "merged_train_df = train_df.merge(properties_df, on='orderID', how='left')\n",
    "# X_train = merged_train_df.drop(columns=columns_to_drop_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test\n",
    "import ast\n",
    "\n",
    "properties = test_df[['orderID', 'properties']]\n",
    "\n",
    "records = []\n",
    "for _, row in properties.iterrows():\n",
    "    orderID = row['orderID']\n",
    "    prop_list = row['properties']\n",
    "    prop_list = ast.literal_eval(prop_list)\n",
    "    if isinstance(prop_list, str):\n",
    "        try:\n",
    "            prop_list = json.loads(prop_list.replace(\"'\", '\"'))\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    for prop in prop_list:\n",
    "        prop_record = {\n",
    "            \"orderID\": orderID,\n",
    "            \"id\":prop.get(\"id\", None),\n",
    "            \"address\": prop.get(\"address\", None),\n",
    "            \"bedrooms\": prop.get(\"bedrooms\", None),\n",
    "            \"gla\": prop.get(\"gla\", None),\n",
    "            \"city\": prop.get(\"city\", None),\n",
    "            \"province\": prop.get(\"province\", None),\n",
    "            \"postal_code\": prop.get(\"postal_code\", None),\n",
    "            \"property_sub_type\": prop.get(\"property_sub_type\", None),\n",
    "            \"structure_type\": prop.get(\"structure_type\", None),\n",
    "            \"style\": prop.get(\"style\", None),\n",
    "            \"levels\": prop.get(\"levels\", None),\n",
    "            \"room_count\": prop.get(\"room_count\", None),\n",
    "            \"full_baths\": prop.get(\"full_baths\", None),\n",
    "            \"half_baths\": prop.get(\"half_baths\", None),\n",
    "            \"lot_size_sf\": prop.get(\"lot_size_sf\", None),\n",
    "            \"year_built\": prop.get(\"year_built\", None),\n",
    "            \"roof\": prop.get(\"roof\", None),\n",
    "            \"basement\": prop.get(\"basement\", None),\n",
    "            \"cooling\": prop.get(\"cooling\", None),\n",
    "            \"heating\": prop.get(\"heating\", None),\n",
    "        }\n",
    "        records.append(prop_record)\n",
    "\n",
    "properties_df = pd.DataFrame(records)\n",
    "properties_df = properties_df.rename(columns={\n",
    "    col: f\"prop.{col}\" for col in properties_df.columns if col != \"orderID\"\n",
    "})\n",
    "merged_test_df = train_df.merge(properties_df, on='orderID', how='left')\n",
    "# X_test = merged_test_df.drop(columns=columns_to_drop_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3c483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def standardize_and_split_address(address):\n",
    "    \n",
    "    if pd.isna(address):\n",
    "        return pd.Series([None, None, None, None])\n",
    "    \n",
    "    addr = str(address).strip().replace('\"', '').replace(\"'\", \"\")\n",
    "    \n",
    "    # Extract postal code using Canadian postal code pattern\n",
    "    postal_code_pattern = r'([A-Za-z]\\d[A-Za-z][ -]?\\d[A-Za-z]\\d)'\n",
    "    postal_code_match = re.search(postal_code_pattern, addr)\n",
    "    postal_code = postal_code_match.group(1) if postal_code_match else None\n",
    "    \n",
    "    if postal_code:\n",
    "        addr_wo_postal = addr.replace(postal_code, '').strip(', ')\n",
    "    else:\n",
    "        addr_wo_postal = addr\n",
    "    \n",
    "    # Check if address contains commas\n",
    "    if ',' in addr_wo_postal:\n",
    "        parts = [p.strip() for p in addr_wo_postal.split(',') if p.strip()]\n",
    "        \n",
    "        province = None\n",
    "        city = None\n",
    "        address_part = None\n",
    "        \n",
    "        if len(parts) >= 2:\n",
    "            province_match = re.search(r'\\b([A-Z]{2})\\b', parts[-1])\n",
    "            if province_match:\n",
    "                province = province_match.group(1)\n",
    "                city = parts[-2]\n",
    "                address_part = ', '.join(parts[:-2])\n",
    "            else:\n",
    "                city = parts[-1]\n",
    "                address_part = ', '.join(parts[:-1])\n",
    "        elif len(parts) == 1:\n",
    "            address_part = parts[0]\n",
    "        else:\n",
    "            address_part = addr_wo_postal\n",
    "    else:\n",
    "        # Space separated, try to parse from tokens\n",
    "        tokens = addr_wo_postal.split()\n",
    "        \n",
    "        province = None\n",
    "        city = None\n",
    "        address_part = None\n",
    "        \n",
    "        # Assume last token is province if it is 2 uppercase letters\n",
    "        if len(tokens) >= 2 and re.fullmatch(r'[A-Z]{2}', tokens[-1]):\n",
    "            province = tokens[-1]\n",
    "            if province == \"ON\":\n",
    "                province = \"Ontario\"\n",
    "            elif province == \"BC\":\n",
    "                province = \"British Columbia\"\n",
    "            elif province == \"AB\":\n",
    "                province = \"Alberta\"\n",
    "            elif province == \"NS\": \n",
    "                province = \"Nova Scotia\"\n",
    "            elif province == \"None\":\n",
    "                return np.nan\n",
    "            city = tokens[-2]\n",
    "            address_part = \" \".join(tokens[:-2])\n",
    "        elif len(tokens) >= 1:\n",
    "            # fallback if no province token detected\n",
    "            address_part = \" \".join(tokens[:-1])\n",
    "            city = tokens[-1]\n",
    "        else:\n",
    "            address_part = addr_wo_postal\n",
    "    \n",
    "    return pd.Series([address_part, city, province, postal_code])\n",
    "\n",
    "# Apply to normalized_df\n",
    "merged_train_df[['subject.address', 'subject.city', 'subject.province', 'subject.postal_code']] = merged_train_df['subject.address'].apply(standardize_and_split_address)\n",
    "merged_test_df[['subject.address', 'subject.city', 'subject.province', 'subject.postal_code']] = merged_test_df['subject.address'].apply(standardize_and_split_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cafdd628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gla(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value.replace('.','',1).isdigit():\n",
    "        \n",
    "        return float(value)\n",
    "    value = value.replace('+/-','')\n",
    "    match = re.search(r\"([\\d.]+)\", value)\n",
    "    if not match:\n",
    "        return np.nan\n",
    "    number = float(match[0]) \n",
    "    if any(x in value for x in ['sqm']):\n",
    "        return number * 10.7639\n",
    "    elif any(x in value for x in ['sqft', 'sf']):\n",
    "        return float(number)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "\n",
    "merged_train_df['subject.gla_parsed'] = merged_train_df['subject.gla'].apply(parse_gla)\n",
    "merged_test_df['subject.gla_parsed'] = merged_test_df['subject.gla'].apply(parse_gla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0039ea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1504.0\n",
       "1       1504.0\n",
       "2       1504.0\n",
       "3       1504.0\n",
       "4       1504.0\n",
       "         ...  \n",
       "8124       1.0\n",
       "8125       1.0\n",
       "8126       1.0\n",
       "8127       1.0\n",
       "8128       1.0\n",
       "Name: subject.gla_parsed, Length: 8129, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train_df['subject.gla_parsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120a0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_year_built(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    value = str(value).strip().lower()\n",
    "    if value == \"new\":\n",
    "        return 2025\n",
    "    if value.isdigit():\n",
    "        return float(value)\n",
    "    if value.replace('.','',1).isdigit():\n",
    "        return float(value)\n",
    "    match = re.search(r\"([\\d.]+)\", value)\n",
    "    if not match:\n",
    "        return np.nan\n",
    "    number = float(match[0]) \n",
    "    return number\n",
    "\n",
    "merged_train_df['subject.year_built_parsed'] = merged_train_df['subject.year_built'].apply(parse_year_built)\n",
    "merged_test_df['subject.year_built_parsed'] = merged_test_df['subject.year_built'].apply(parse_year_built)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda501db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_year_built(value):\n",
    "    try:\n",
    "        # Convert from scientific notation or string to float\n",
    "        year = float(value)\n",
    "        year = int(round(year))  # Convert to integer\n",
    "        \n",
    "        current_year = datetime.now().year\n",
    "        \n",
    "        # Handle likely invalid placeholder years (e.g., 40, 8, 13)\n",
    "        if year < 100:  \n",
    "            return np.nan\n",
    "\n",
    "        # Handle likely valid years (e.g., 1900â€“current year)\n",
    "        if 1800 <= year <= current_year:\n",
    "            return year\n",
    "        \n",
    "        return np.nan  # Drop anything else\n",
    "    except:\n",
    "        return np.nan\n",
    "merged_train_df['prop.year_built_parsed'] = merged_train_df['prop.year_built'].apply(clean_year_built)\n",
    "merged_test_df['prop.year_built_parsed'] = merged_test_df['prop.year_built'].apply(clean_year_built)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "739f3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_num_baths(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value.isdigit():\n",
    "        return float(value)\n",
    "    full = 0\n",
    "    half = 0\n",
    "    if ':' in value:\n",
    "        parts = value.split(':') \n",
    "        full = float(parts[0])\n",
    "        half = float(parts[1]) if len(parts) > 1 else 0\n",
    "    elif 'f' in value or 'h' in value:\n",
    "        full_match = re.search(r'(\\d+)f', value)\n",
    "        if full_match:\n",
    "            full = float(full_match.group(1))\n",
    "        half_match = re.search(r'(\\d+)h', value)\n",
    "        if half_match:\n",
    "            half = float(half_match.group(1))\n",
    "    elif 'full' in value or 'half' in value:\n",
    "        full_match = re.search(r'(\\d+)full', value)\n",
    "        if full_match:\n",
    "            full = float(full_match.group(1))\n",
    "        half_match = re.search(r'(\\d+)half', value)\n",
    "        if half_match:\n",
    "            half = float(half_match.group(1))\n",
    "    return full + (0.5 * half)\n",
    "    \n",
    "merged_train_df['subject.num_baths_parsed'] = merged_train_df['subject.num_baths'].apply(parse_num_baths)\n",
    "merged_test_df['subject.num_baths_parsed'] = merged_test_df['subject.num_baths'].apply(parse_num_baths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea3eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_bathrooms(df, full_col='full_baths', half_col='half_baths', new_col='num_baths'):\n",
    "    df = df.copy()\n",
    "    \n",
    "    full = df[full_col].fillna(0).astype(float)\n",
    "    half = df[half_col].fillna(0).astype(float)\n",
    "    \n",
    "    df[new_col] = full + 0.5 * half\n",
    "    return df\n",
    "merged_train_df = combine_bathrooms(merged_train_df, full_col='prop.full_baths', half_col='prop.half_baths', new_col='prop.num_baths')\n",
    "merged_test_df = combine_bathrooms(merged_test_df, full_col='prop.full_baths', half_col='prop.half_baths', new_col='prop.num_baths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "563a8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_room_count(value):\n",
    "    \"\"\"\n",
    "    Parse and standardize room count values such as '3', '3+1', '2+2', nan, etc.\n",
    "    Returns a float or np.nan.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip()\n",
    "    if not value:\n",
    "        return np.nan\n",
    "    # Handle values like '3+1', '2+2'\n",
    "    if '+' in value:\n",
    "        try:\n",
    "            parts = [float(x) for x in value.split('+') if x.strip().isdigit()]\n",
    "            return sum(parts)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    # Handle simple numeric values\n",
    "    try:\n",
    "        return float(value)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "merged_train_df['subject.num_beds_parsed'] = merged_train_df['subject.num_beds'].apply(parse_room_count)\n",
    "merged_test_df['subject.num_beds_parsed'] = merged_test_df['subject.num_beds'].apply(parse_room_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df2b9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_lot_size_sf(lot_size):\n",
    "    if pd.isna(lot_size):\n",
    "        return np.nan\n",
    "    lot_size = lot_size.lower().strip()\n",
    "    if any(x in lot_size.lower() for x in ['n/a','na','nan']):\n",
    "        return np.nan\n",
    "    value = lot_size.replace('+/-','')\n",
    "    match = re.search(r\"([\\d.]+)\", value)\n",
    "    if not match:\n",
    "        return np.nan\n",
    "    number = float(match[0])\n",
    "    if any(x in value for x in ['acres', 'acre','ac']):\n",
    "        return number * 43560\n",
    "    elif any(x in value for x in ['sqm','sq m']):\n",
    "        return number * 10.7639\n",
    "    elif any(x in value for x in ['sqft']):\n",
    "        return number\n",
    "    else:\n",
    "        return np.nan  \n",
    "\n",
    "merged_train_df['subject.lot_size_sf_parsed'] = merged_train_df['subject.lot_size_sf'].apply(parse_lot_size_sf)\n",
    "merged_train_df['prop.lot_size_sf_parsed'] = merged_train_df['subject.lot_size_sf'].apply(parse_lot_size_sf)\n",
    "merged_test_df['subject.lot_size_sf_parsed'] = merged_test_df['subject.lot_size_sf'].apply(parse_lot_size_sf)\n",
    "merged_test_df['prop.lot_size_sf_parsed'] = merged_test_df['subject.lot_size_sf'].apply(parse_lot_size_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8918d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_X = ['comps','properties', 'subject.basement_area', 'subject.condition',\n",
    "       'subject.construction', 'subject.effective_date','subject.lot_size_sf','subject.year_built',\n",
    "       'subject.exterior_finish', 'subject.flooring','subject.room_count',\n",
    "       'subject.foundation_walls', 'subject.fuel_type', \n",
    "       'subject.main_lvl_area', 'subject.municipality_district',\n",
    "       'subject.plumbing_lines', 'subject.remaining_economic_life',\n",
    "       'subject.room_total', 'subject.second_lvl_area','subject.num_beds',\n",
    "       'subject.site_dimensions', 'subject.subject_city_province_zip',\n",
    "       'subject.third_lvl_area', 'subject.units_sq_ft', 'subject.water_heater','subject.num_baths','prop.full_baths',\n",
    "       'prop.half_baths','prop.lot_size_sf','prop.year_built',\n",
    "       'subject.windows','prop.property_sub_type', 'subject.roofing', 'subject.gla','prop.bedrooms','prop.room_count']\n",
    "merged_train_df['subject.roof'] = merged_train_df['subject.roofing']\n",
    "merged_train_df['prop.num_beds'] = merged_train_df['prop.bedrooms']\n",
    "X_train = merged_train_df.drop(columns=columns_to_drop_X)\n",
    "X_test = merged_test_df.drop(columns=columns_to_drop_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab5fa537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderID', 'subject.address', 'subject.structure_type',\n",
       "       'subject.effective_age', 'subject.style', 'subject.basement',\n",
       "       'subject.heating', 'subject.cooling', 'subject.subject_age', 'prop.id',\n",
       "       'prop.address', 'prop.gla', 'prop.city', 'prop.province',\n",
       "       'prop.postal_code', 'prop.structure_type', 'prop.style', 'prop.levels',\n",
       "       'prop.roof', 'prop.basement', 'prop.cooling', 'prop.heating',\n",
       "       'subject.city', 'subject.province', 'subject.postal_code',\n",
       "       'subject.gla_parsed', 'subject.year_built_parsed',\n",
       "       'prop.year_built_parsed', 'subject.num_baths_parsed', 'prop.num_baths',\n",
       "       'subject.num_beds_parsed', 'subject.lot_size_sf_parsed',\n",
       "       'prop.lot_size_sf_parsed', 'subject.roof', 'prop.num_beds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a66b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8129 entries, 0 to 8128\n",
      "Data columns (total 35 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   orderID                     8129 non-null   int64  \n",
      " 1   subject.address             8129 non-null   object \n",
      " 2   subject.structure_type      8129 non-null   object \n",
      " 3   subject.effective_age       8129 non-null   object \n",
      " 4   subject.style               8129 non-null   object \n",
      " 5   subject.basement            6652 non-null   object \n",
      " 6   subject.heating             8129 non-null   object \n",
      " 7   subject.cooling             5539 non-null   object \n",
      " 8   subject.subject_age         8129 non-null   object \n",
      " 9   prop.id                     8129 non-null   int64  \n",
      " 10  prop.address                8129 non-null   object \n",
      " 11  prop.gla                    7978 non-null   float64\n",
      " 12  prop.city                   8126 non-null   object \n",
      " 13  prop.province               8129 non-null   object \n",
      " 14  prop.postal_code            8096 non-null   object \n",
      " 15  prop.structure_type         8120 non-null   object \n",
      " 16  prop.style                  8110 non-null   object \n",
      " 17  prop.levels                 7923 non-null   object \n",
      " 18  prop.roof                   7638 non-null   object \n",
      " 19  prop.basement               8111 non-null   object \n",
      " 20  prop.cooling                8109 non-null   object \n",
      " 21  prop.heating                8061 non-null   object \n",
      " 22  subject.city                8129 non-null   object \n",
      " 23  subject.province            7555 non-null   object \n",
      " 24  subject.postal_code         8129 non-null   object \n",
      " 25  subject.gla_parsed          8129 non-null   float64\n",
      " 26  subject.year_built_parsed   8129 non-null   float64\n",
      " 27  prop.year_built_parsed      4539 non-null   float64\n",
      " 28  subject.num_baths_parsed    8129 non-null   float64\n",
      " 29  prop.num_baths              8129 non-null   float64\n",
      " 30  subject.num_beds_parsed     8129 non-null   float64\n",
      " 31  subject.lot_size_sf_parsed  5250 non-null   float64\n",
      " 32  prop.lot_size_sf_parsed     5250 non-null   float64\n",
      " 33  subject.roof                8129 non-null   object \n",
      " 34  prop.num_beds               7981 non-null   float64\n",
      "dtypes: float64(10), int64(2), object(23)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0503ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train\n",
    "comps = train_df[['orderID', 'comps']]\n",
    "records = []\n",
    "for _, row in comps.iterrows():\n",
    "    orderID = row['orderID']\n",
    "    prop_list = row['comps']\n",
    "    prop_list = ast.literal_eval(prop_list)\n",
    "    for prop in prop_list:\n",
    "    \n",
    "        prop_record = {\n",
    "            \"orderID\": orderID,\n",
    "            \"distance_to_subject\": prop.get('distance_to_subject', None),\n",
    "          \"prop_type\": prop.get('prop_type', None),\n",
    "          \"stories\": prop.get('stories', None),\n",
    "          \"address\": prop.get('address', None),\n",
    "          \"city_province\": prop.get('city_province', None),\n",
    "          \"sale_date\": prop.get('sale_date', None),\n",
    "          \"sale_price\": prop.get('sale_price', None),\n",
    "          \"dom\": prop.get('dom', None),\n",
    "          \"location_similarity\":prop.get('location_similarity', None),\n",
    "          \"lot_size\": prop.get('lot_size', None),\n",
    "          \"age\":  prop.get('age', None),\n",
    "          \"condition\": prop.get('condition', None), \n",
    "          \"gla\": prop.get('gla', None),\n",
    "          \"room_count\": prop.get('room_count', None),\n",
    "          \"bed_count\":  prop.get('bed_count', None),\n",
    "          \"bath_count\": prop.get('bath_count', None),\n",
    "          \"basement_finish\": prop.get('basement_finish', None),\n",
    "          \"parking\": prop.get('parking', None),\n",
    "          \"neighborhood\": prop.get('neighborhood', None)\n",
    "        }\n",
    "        records.append(prop_record)\n",
    "\n",
    "comps_train_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "824ddc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test\n",
    "comps = test_df[['orderID', 'comps']]\n",
    "records = []\n",
    "for _, row in comps.iterrows():\n",
    "    orderID = row['orderID']\n",
    "    prop_list = row['comps']\n",
    "    prop_list = ast.literal_eval(prop_list)\n",
    "   \n",
    "    for prop in prop_list:\n",
    "    \n",
    "        prop_record = {\n",
    "            \"orderID\": orderID,\n",
    "            \"distance_to_subject\": prop.get('distance_to_subject', None),\n",
    "          \"prop_type\": prop.get('prop_type', None),\n",
    "          \"stories\": prop.get('stories', None),\n",
    "          \"address\": prop.get('address', None),\n",
    "          \"city_province\": prop.get('city_province', None),\n",
    "          \"sale_date\": prop.get('sale_date', None),\n",
    "          \"sale_price\": prop.get('sale_price', None),\n",
    "          \"dom\": prop.get('dom', None),\n",
    "          \"location_similarity\":prop.get('location_similarity', None),\n",
    "          \"lot_size\": prop.get('lot_size', None),\n",
    "          \"age\":  prop.get('age', None),\n",
    "          \"condition\": prop.get('condition', None), \n",
    "          \"gla\": prop.get('gla', None),\n",
    "          \"room_count\": prop.get('room_count', None),\n",
    "          \"bed_count\":  prop.get('bed_count', None),\n",
    "          \"bath_count\": prop.get('bath_count', None),\n",
    "          \"basement_finish\": prop.get('basement_finish', None),\n",
    "          \"parking\": prop.get('parking', None),\n",
    "          \"neighborhood\": prop.get('neighborhood', None)\n",
    "        }\n",
    "        records.append(prop_record)\n",
    "comps_test_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e786791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderID', 'distance_to_subject', 'prop_type', 'stories', 'address',\n",
       "       'city_province', 'sale_date', 'sale_price', 'dom',\n",
       "       'location_similarity', 'lot_size', 'age', 'condition', 'gla',\n",
       "       'room_count', 'bed_count', 'bath_count', 'basement_finish', 'parking',\n",
       "       'neighborhood'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d627c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps_train_df['num_beds_parsed'] = comps_train_df['bed_count'].apply(parse_room_count)\n",
    "comps_test_df['num_beds_parsed'] = comps_test_df['bed_count'].apply(parse_room_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5b5cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps_train_df['num_baths_parsed'] = comps_train_df['bath_count'].apply(parse_num_baths)\n",
    "comps_test_df['num_baths_parsed'] = comps_test_df['bath_count'].apply(parse_num_baths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70b0f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comps_train_df['gla_parsed'] = comps_train_df['gla'].apply(parse_gla)\n",
    "comps_test_df['gla_parsed'] = comps_test_df['gla'].apply(parse_gla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e628ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_age(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    value = str(value).strip().lower()\n",
    "    if value == \"new\":\n",
    "        return 0\n",
    "    if value.isdigit():\n",
    "        age = float(value)\n",
    "        if 1900 <= age <= 2025:\n",
    "            return 2025-age\n",
    "        return age\n",
    "    if value.replace('.','',1).isdigit():\n",
    "        return float(value)\n",
    "    match = re.search(r\"([\\d.]+)\", value)\n",
    "    if not match:\n",
    "        return np.nan\n",
    "    number = float(match[0]) \n",
    "    if 1900 <= number <= 2025:\n",
    "        return 2025-number\n",
    "    return number\n",
    "\n",
    "comps_train_df['age_parsed'] = comps_train_df['age'].apply(parse_age)\n",
    "comps_test_df['age_parsed'] = comps_test_df['age'].apply(parse_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c51071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_site_dimensions(dimension):\n",
    "    if pd.isna(dimension):\n",
    "        return np.nan\n",
    "    dimension = str(dimension).strip().lower()\n",
    "    if any(x in dimension for x in ['condo','common property', 'see','n/a','unknown','not applicable']):\n",
    "        return np.nan\n",
    "    try:\n",
    "        if dimension.replace('.','',1).isdigit():\n",
    "            return float(dimension)\n",
    "        if 'acre' in dimension:\n",
    "            acres = float(dimension.split()[0])\n",
    "            return acres * 43560\n",
    "        \n",
    "        dims = dimension.replace(\"'\",'').replace('\"','').replace('ft','').replace('f','')\n",
    "        dims = dims.replace('x',' ').replace('X',' ').replace('by',' ')\n",
    "        dims = dims.replace('m','').replace('irregular','').replace('irr','')\n",
    "        dims = dims.strip().split()\n",
    "        if len(dims) >= 2:\n",
    "\n",
    "            length = float(dims[0])\n",
    "            width = float(dims[1])\n",
    "            if any(x in dimension.lower() for x in ['m','metre', 'meter']):\n",
    "                length = length * 3.28084\n",
    "                width = width * 3.28084\n",
    "            return length * width\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "    return\n",
    "comps_train_df['lot_size_parsed'] = comps_train_df['lot_size'].apply(parse_site_dimensions)\n",
    "comps_test_df['lot_size_parsed'] = comps_test_df['lot_size'].apply(parse_site_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eef67af",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_y = ['distance_to_subject','sale_date','sale_price','dom','location_similarity','condition','parking','neighborhood','lot_size','age','bed_count','bath_count', 'gla','room_count']\n",
    "y_train = comps_train_df.drop(columns=columns_to_drop_y)\n",
    "y_test = comps_test_df.drop(columns=columns_to_drop_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891254ef",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ef7fcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderID', 'subject.address', 'subject.structure_type',\n",
       "       'subject.effective_age', 'subject.style', 'subject.basement',\n",
       "       'subject.heating', 'subject.cooling', 'subject.subject_age', 'prop.id',\n",
       "       'prop.address', 'prop.gla', 'prop.city', 'prop.province',\n",
       "       'prop.postal_code', 'prop.structure_type', 'prop.style', 'prop.levels',\n",
       "       'prop.roof', 'prop.basement', 'prop.cooling', 'prop.heating',\n",
       "       'subject.city', 'subject.province', 'subject.postal_code',\n",
       "       'subject.gla_parsed', 'subject.year_built_parsed',\n",
       "       'prop.year_built_parsed', 'subject.num_baths_parsed', 'prop.num_baths',\n",
       "       'subject.num_beds_parsed', 'subject.lot_size_sf_parsed',\n",
       "       'prop.lot_size_sf_parsed', 'subject.roof', 'prop.num_beds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51529c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f073a49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderID', 'prop_type', 'stories', 'address', 'city_province',\n",
       "       'basement_finish', 'num_beds_parsed', 'num_baths_parsed', 'gla_parsed',\n",
       "       'age_parsed', 'lot_size_parsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be582c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example dataframe\n",
    "df = X_train.copy()  # replace with your actual dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "851a073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   orderID               top_comps\n",
      "0  4768126  [92565, 80203, 287677]\n",
      "1  4777578  [92565, 80203, 287677]\n",
      "2  4761220  [92565, 80203, 287677]\n",
      "3  4758324  [92565, 80203, 287677]\n",
      "4  4759562  [92565, 80203, 287677]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# List of numerical columns only\n",
    "numerical_features = [\n",
    "    'subject.year_built_parsed', 'prop.year_built_parsed',\n",
    "    'subject.num_baths_parsed', 'prop.num_baths',\n",
    "    'subject.num_beds_parsed', 'prop.num_beds',\n",
    "    'subject.lot_size_sf_parsed', 'prop.lot_size_sf_parsed',\n",
    "    'subject.gla_parsed', 'prop.gla'\n",
    "]\n",
    "\n",
    "# Subset your dataframe\n",
    "X = df[numerical_features]\n",
    "# display(X.info())\n",
    "\n",
    "# Separate into subject and prop features\n",
    "subject_features = X[[col for col in numerical_features if col.startswith('subject.')]]\n",
    "prop_features = X[[col for col in numerical_features if col.startswith('prop.')]]\n",
    "\n",
    "# # Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "subject_imputed = imputer.fit_transform(subject_features)\n",
    "prop_imputed = imputer.fit_transform(prop_features)  # Use fit_transform here if train/test split not used\n",
    "\n",
    "# # Scale the features\n",
    "scaler = StandardScaler()\n",
    "subject_scaled = scaler.fit_transform(subject_imputed)\n",
    "prop_scaled = scaler.fit_transform(prop_imputed)  # Use fit_transform here too for now\n",
    "\n",
    "# # Compute cosine similarity\n",
    "similarity_matrix = cosine_similarity(subject_scaled, prop_scaled)\n",
    "\n",
    "# Create DataFrame with orderID and top-3 prop.id for each subject\n",
    "# import numpy as np\n",
    "\n",
    "top_k = 3\n",
    "results = []\n",
    "for i, order_id in enumerate(df['orderID'].unique()):\n",
    "    row_sim = similarity_matrix[i]\n",
    "    top_indices = np.argsort(row_sim)[-top_k:][::-1]\n",
    "    top_prop_ids = df.iloc[top_indices]['prop.id'].tolist()\n",
    "    results.append({\n",
    "        'orderID': order_id,\n",
    "        'top_comps': top_prop_ids\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22622795",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_comp_features = ['gla_parsed', 'room_count', 'num_beds_parsed', \n",
    "                      'num_baths_parsed', 'age_parsed', 'lot_size_parsed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2667b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   orderID           210 non-null    int64  \n",
      " 1   prop_type         210 non-null    object \n",
      " 2   stories           210 non-null    object \n",
      " 3   address           210 non-null    object \n",
      " 4   city_province     210 non-null    object \n",
      " 5   basement_finish   210 non-null    object \n",
      " 6   num_beds_parsed   210 non-null    float64\n",
      " 7   num_baths_parsed  210 non-null    float64\n",
      " 8   gla_parsed        210 non-null    float64\n",
      " 9   age_parsed        210 non-null    float64\n",
      " 10  lot_size_parsed   62 non-null     float64\n",
      "dtypes: float64(5), int64(1), object(5)\n",
      "memory usage: 18.2+ KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55a7789f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prop_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m prop_vecs_by_order \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, oid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(order_ids):\n\u001b[1;32m---> 29\u001b[0m     prop_vecs_by_order[oid]\u001b[38;5;241m.\u001b[39mappend((\u001b[43mprop_ids\u001b[49m[idx], prop_scaled[idx]))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Now compute similarity\u001b[39;00m\n\u001b[0;32m     32\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prop_ids' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# Group the true comps by orderID\n",
    "true_comps_by_order = y_train.groupby('orderID')\n",
    "order_ids = X_train['orderID'].values  # or df['orderID'].values\n",
    "# Map from orderID to indices in prediction set\n",
    "order_to_indices = defaultdict(list)\n",
    "for idx, oid in enumerate(order_ids):\n",
    "    order_to_indices[oid].append(idx)\n",
    "\n",
    "# Feature columns to compare\n",
    "feature_cols = ['gla_parsed', 'num_beds_parsed', \n",
    "                'num_baths_parsed', 'age_parsed', 'lot_size_parsed']\n",
    "\n",
    "# Normalize true comp features\n",
    "true_comp_vectors = {}\n",
    "for oid, group in true_comps_by_order:\n",
    "    comps = group[feature_cols].dropna()\n",
    "    if not comps.empty:\n",
    "        # Store as a matrix of shape (num_comps, num_features)\n",
    "        true_comp_vectors[oid] = comps.to_numpy(dtype=np.float32)\n",
    "\n",
    "# Map from (orderID, propID) -> vector\n",
    "prop_vecs_by_order = defaultdict(list)\n",
    "for idx, oid in enumerate(order_ids):\n",
    "    prop_vecs_by_order[oid].append((prop_ids[idx], prop_scaled[idx]))\n",
    "\n",
    "# Now compute similarity\n",
    "results = []\n",
    "\n",
    "for oid in true_comp_vectors:\n",
    "    if oid not in prop_vecs_by_order:\n",
    "        continue\n",
    "\n",
    "    pred_vectors = [vec for _, vec in prop_vecs_by_order[oid]]\n",
    "    pred_ids = [pid for pid, _ in prop_vecs_by_order[oid]]\n",
    "\n",
    "    pred_matrix = np.vstack(pred_vectors)\n",
    "    true_matrix = true_comp_vectors[oid]\n",
    "\n",
    "    # For each predicted comp, find the max similarity to any true comp\n",
    "    sim_matrix = cosine_similarity(pred_matrix, true_matrix)  # shape: [#pred, #true]\n",
    "\n",
    "    top_k = min(3, sim_matrix.shape[0])\n",
    "    top_k_avg = []\n",
    "\n",
    "    for i in range(top_k):\n",
    "        sim_row = sim_matrix[i]  # similarities of this predicted comp to all true comps\n",
    "        top_sim = np.max(sim_row)\n",
    "        top_k_avg.append(top_sim)\n",
    "\n",
    "    avg_similarity = np.mean(top_k_avg)\n",
    "    results.append((oid, avg_similarity))\n",
    "\n",
    "# Create results DataFrame\n",
    "similarity_df = pd.DataFrame(results, columns=['orderID', 'avg_similarity'])\n",
    "print(f\"Mean cosine similarity across all orders: {similarity_df['avg_similarity'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc116e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderID', 'prop_type', 'stories', 'address', 'city_province', 'gla',\n",
       "       'room_count', 'basement_finish', 'num_beds_parsed', 'num_baths_parsed',\n",
       "       'gla_parsed', 'age_parsed', 'lot_size_parsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc541ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b595d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract orderID array\n",
    "order_ids = df['orderID'].values\n",
    "\n",
    "# Map top 3 prop indices to prop ids (already done)\n",
    "top_3_prop_ids = prop_ids[top_3_prop_indices]\n",
    "\n",
    "# Create a DataFrame with orderID and top 3 comps prop IDs\n",
    "results_df = pd.DataFrame({\n",
    "    'orderID': order_ids,\n",
    "    'comp_1_prop_id': top_3_prop_ids[:, 0],\n",
    "    'comp_2_prop_id': top_3_prop_ids[:, 1],\n",
    "    'comp_3_prop_id': top_3_prop_ids[:, 2],\n",
    "})\n",
    "\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ffa3cd",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76603200",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[377], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      7\u001b[0m     orderID \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morderID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m     prop_list \u001b[38;5;241m=\u001b[39m \u001b[43mddd\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m     prop_list \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(prop_list)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# print(prop_list)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# print(type(prop_list))\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ddd' is not defined"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "properties = df[['orderID', 'properties']]\n",
    "\n",
    "records = []\n",
    "for _, row in properties.iterrows():\n",
    "    orderID = row['orderID']\n",
    "    prop_list = ddd['properties']\n",
    "    prop_list = ast.literal_eval(prop_list)\n",
    "    # print(prop_list)\n",
    "    # print(type(prop_list))\n",
    "\n",
    "\n",
    "    if isinstance(prop_list, str):\n",
    "        try:\n",
    "            prop_list = json.loads(prop_list.replace(\"'\", '\"'))\n",
    "        except Exception as e:\n",
    "            # print(f\"Skipping row with orderID {orderID} due to JSON error: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not isinstance(prop_list, list):\n",
    "        continue\n",
    "    # print(\"here\")\n",
    "    for prop in prop_list:\n",
    "    \n",
    "        prop_record = {\n",
    "            \"orderID\": orderID,\n",
    "            \"id\":prop.get(\"id\", None),\n",
    "            \"address\": prop.get(\"address\", None),\n",
    "            \"bedrooms\": prop.get(\"bedrooms\", None),\n",
    "            \"gla\": prop.get(\"gla\", None),\n",
    "            \"city\": prop.get(\"city\", None),\n",
    "            \"province\": prop.get(\"province\", None),\n",
    "            \"postal_code\": prop.get(\"postal_code\", None),\n",
    "            \"property_sub_type\": prop.get(\"property_sub_type\", None),\n",
    "            \"structure_type\": prop.get(\"structure_type\", None),\n",
    "            \"style\": prop.get(\"style\", None),\n",
    "            \"levels\": prop.get(\"levels\", None),\n",
    "            \"room_count\": prop.get(\"room_count\", None),\n",
    "            \"full_baths\": prop.get(\"full_baths\", None),\n",
    "            \"half_baths\": prop.get(\"half_baths\", None),\n",
    "            # \"main_level_finished_area\": prop.get(\"main_level_finished_area\", None),\n",
    "            # \"upper_lvl_fin_area\": prop.get(\"upper_lvl_fin_area\", None),\n",
    "            # \"bg_fin_area\": prop.get(\"bg_fin_area\", None),\n",
    "            \"lot_size_sf\": prop.get(\"lot_size_sf\", None),\n",
    "            \"year_built\": prop.get(\"year_built\", None),\n",
    "            \"roof\": prop.get(\"roof\", None),\n",
    "            \"basement\": prop.get(\"basement\", None),\n",
    "            \"cooling\": prop.get(\"cooling\", None),\n",
    "            \"heating\": prop.get(\"heating\", None),\n",
    "            # \"close_price\": prop.get(\"close_price\", None),\n",
    "            # \"close_date\": prop.get(\"close_date\", None),\n",
    "            # \"public_remarks\": prop.get(\"public_remarks\", None),\n",
    "            # \"latitude\": prop.get(\"latitude\", None),\n",
    "            # \"longitude\": prop.get(\"longitude\", None),\n",
    "        }\n",
    "        records.append(prop_record)\n",
    "\n",
    "properties_df = pd.DataFrame(records)\n",
    "properties_df = properties_df.rename(columns={\n",
    "    col: f\"prop.{col}\" for col in properties_df.columns if col != \"orderID\"\n",
    "})\n",
    "display(properties_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc37cd0",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderID', 'comps', 'properties', 'subject.address',\n",
       "       'subject.subject_city_province_zip', 'subject.effective_date',\n",
       "       'subject.municipality_district', 'subject.site_dimensions',\n",
       "       'subject.lot_size_sf', 'subject.units_sq_ft', 'subject.year_built',\n",
       "       'subject.structure_type', 'subject.roofing', 'subject.effective_age',\n",
       "       'subject.style', 'subject.construction',\n",
       "       'subject.remaining_economic_life', 'subject.windows',\n",
       "       'subject.basement', 'subject.exterior_finish', 'subject.basement_area',\n",
       "       'subject.foundation_walls', 'subject.flooring',\n",
       "       'subject.plumbing_lines', 'subject.heating', 'subject.fuel_type',\n",
       "       'subject.water_heater', 'subject.cooling', 'subject.room_count',\n",
       "       'subject.num_beds', 'subject.room_total', 'subject.main_lvl_area',\n",
       "       'subject.second_lvl_area', 'subject.third_lvl_area', 'subject.gla',\n",
       "       'subject.subject_age', 'subject.num_baths', 'subject.condition',\n",
       "       'prop.id', 'prop.address', 'prop.bedrooms', 'prop.gla', 'prop.city',\n",
       "       'prop.province', 'prop.postal_code', 'prop.property_sub_type',\n",
       "       'prop.structure_type', 'prop.style', 'prop.levels', 'prop.room_count',\n",
       "       'prop.full_baths', 'prop.half_baths', 'prop.lot_size_sf',\n",
       "       'prop.year_built', 'prop.roof', 'prop.basement', 'prop.cooling',\n",
       "       'prop.heating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = df.merge(properties_df, on='orderID', how='left')\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08819463",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped. New shape: (9820, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderID</th>\n",
       "      <th>comps</th>\n",
       "      <th>subject.address</th>\n",
       "      <th>subject.lot_size_sf</th>\n",
       "      <th>subject.year_built</th>\n",
       "      <th>subject.structure_type</th>\n",
       "      <th>subject.roofing</th>\n",
       "      <th>subject.effective_age</th>\n",
       "      <th>subject.style</th>\n",
       "      <th>subject.basement</th>\n",
       "      <th>...</th>\n",
       "      <th>prop.levels</th>\n",
       "      <th>prop.room_count</th>\n",
       "      <th>prop.full_baths</th>\n",
       "      <th>prop.half_baths</th>\n",
       "      <th>prop.lot_size_sf</th>\n",
       "      <th>prop.year_built</th>\n",
       "      <th>prop.roof</th>\n",
       "      <th>prop.basement</th>\n",
       "      <th>prop.cooling</th>\n",
       "      <th>prop.heating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4762597</td>\n",
       "      <td>[{'distance_to_subject': '0.15 KM', 'prop_type...</td>\n",
       "      <td>142-950 Oakview Ave Kingston ON K7M 6W8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Asphalt Shingle</td>\n",
       "      <td>25</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>...</td>\n",
       "      <td>Two</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3555.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Unfinished</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Forced Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4762597</td>\n",
       "      <td>[{'distance_to_subject': '0.15 KM', 'prop_type...</td>\n",
       "      <td>142-950 Oakview Ave Kingston ON K7M 6W8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Asphalt Shingle</td>\n",
       "      <td>25</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>...</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3535.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Unfinished</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Forced Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4762597</td>\n",
       "      <td>[{'distance_to_subject': '0.15 KM', 'prop_type...</td>\n",
       "      <td>142-950 Oakview Ave Kingston ON K7M 6W8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Asphalt Shingle</td>\n",
       "      <td>25</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>...</td>\n",
       "      <td>Two</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Fin W/O</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Forced Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4762597</td>\n",
       "      <td>[{'distance_to_subject': '0.15 KM', 'prop_type...</td>\n",
       "      <td>142-950 Oakview Ave Kingston ON K7M 6W8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Asphalt Shingle</td>\n",
       "      <td>25</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>...</td>\n",
       "      <td>2-Storey</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Finished with Walk-Out</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Forced Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4762597</td>\n",
       "      <td>[{'distance_to_subject': '0.15 KM', 'prop_type...</td>\n",
       "      <td>142-950 Oakview Ave Kingston ON K7M 6W8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Asphalt Shingle</td>\n",
       "      <td>25</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16672.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Part Bsmt, Unfinished</td>\n",
       "      <td>None</td>\n",
       "      <td>Baseboard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   orderID                                              comps  \\\n",
       "0  4762597  [{'distance_to_subject': '0.15 KM', 'prop_type...   \n",
       "1  4762597  [{'distance_to_subject': '0.15 KM', 'prop_type...   \n",
       "2  4762597  [{'distance_to_subject': '0.15 KM', 'prop_type...   \n",
       "3  4762597  [{'distance_to_subject': '0.15 KM', 'prop_type...   \n",
       "4  4762597  [{'distance_to_subject': '0.15 KM', 'prop_type...   \n",
       "\n",
       "                           subject.address subject.lot_size_sf  \\\n",
       "0  142-950 Oakview Ave Kingston ON K7M 6W8                 NaN   \n",
       "1  142-950 Oakview Ave Kingston ON K7M 6W8                 NaN   \n",
       "2  142-950 Oakview Ave Kingston ON K7M 6W8                 NaN   \n",
       "3  142-950 Oakview Ave Kingston ON K7M 6W8                 NaN   \n",
       "4  142-950 Oakview Ave Kingston ON K7M 6W8                 NaN   \n",
       "\n",
       "  subject.year_built subject.structure_type  subject.roofing  \\\n",
       "0               1976              Townhouse  Asphalt Shingle   \n",
       "1               1976              Townhouse  Asphalt Shingle   \n",
       "2               1976              Townhouse  Asphalt Shingle   \n",
       "3               1976              Townhouse  Asphalt Shingle   \n",
       "4               1976              Townhouse  Asphalt Shingle   \n",
       "\n",
       "  subject.effective_age subject.style subject.basement  ... prop.levels  \\\n",
       "0                    25      2 Storey    Full/Finished  ...         Two   \n",
       "1                    25      2 Storey    Full/Finished  ...   2-Storey    \n",
       "2                    25      2 Storey    Full/Finished  ...         Two   \n",
       "3                    25      2 Storey    Full/Finished  ...   2-Storey    \n",
       "4                    25      2 Storey    Full/Finished  ...        None   \n",
       "\n",
       "   prop.room_count prop.full_baths prop.half_baths prop.lot_size_sf  \\\n",
       "0             11.0             3.0             NaN           3555.5   \n",
       "1             11.0             NaN             NaN           3535.0   \n",
       "2             11.0             4.0             NaN           2622.0   \n",
       "3             11.0             NaN             NaN           2622.0   \n",
       "4             13.0             4.0             0.0          16672.0   \n",
       "\n",
       "  prop.year_built  prop.roof            prop.basement  prop.cooling  \\\n",
       "0             NaN       None               Unfinished   Central Air   \n",
       "1             NaN                         Unfinished   Central Air    \n",
       "2             NaN       None                  Fin W/O   Central Air   \n",
       "3             NaN             Finished with Walk-Out   Central Air    \n",
       "4             NaN       None    Part Bsmt, Unfinished          None   \n",
       "\n",
       "   prop.heating  \n",
       "0    Forced Air  \n",
       "1   Forced Air   \n",
       "2    Forced Air  \n",
       "3   Forced Air   \n",
       "4     Baseboard  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['orderID', 'comps', 'subject.address', 'subject.lot_size_sf',\n",
       "       'subject.year_built', 'subject.structure_type', 'subject.roofing',\n",
       "       'subject.effective_age', 'subject.style', 'subject.basement',\n",
       "       'subject.cooling', 'subject.room_count', 'subject.num_beds',\n",
       "       'subject.gla', 'subject.subject_age', 'subject.num_baths', 'prop.id',\n",
       "       'prop.address', 'prop.bedrooms', 'prop.gla', 'prop.city',\n",
       "       'prop.province', 'prop.postal_code', 'prop.property_sub_type',\n",
       "       'prop.structure_type', 'prop.style', 'prop.levels', 'prop.room_count',\n",
       "       'prop.full_baths', 'prop.half_baths', 'prop.lot_size_sf',\n",
       "       'prop.year_built', 'prop.roof', 'prop.basement', 'prop.cooling',\n",
       "       'prop.heating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['properties', 'subject.basement_area', 'subject.condition',\n",
    "       'subject.construction', 'subject.effective_date',\n",
    "       'subject.exterior_finish', 'subject.flooring',\n",
    "       'subject.foundation_walls', 'subject.fuel_type', 'subject.heating',\n",
    "       'subject.main_lvl_area', 'subject.municipality_district',\n",
    "       'subject.plumbing_lines', 'subject.remaining_economic_life',\n",
    "       'subject.room_total', 'subject.second_lvl_area',\n",
    "       'subject.site_dimensions', 'subject.subject_city_province_zip',\n",
    "       'subject.third_lvl_area', 'subject.units_sq_ft', 'subject.water_heater',\n",
    "       'subject.windows']\n",
    "data = merged_df.drop(columns=columns_to_drop)\n",
    "print(\"Columns dropped. New shape:\", data.shape)\n",
    "display(data.head())\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def standardize_and_split_address(address):\n",
    "    \"\"\"\n",
    "    Splits an address string into address, city, province, and postal_code.\n",
    "    Returns a pandas Series: (address, city, province, postal_code)\n",
    "    Handles both comma-separated and space-separated addresses.\n",
    "    \"\"\"\n",
    "    if pd.isna(address):\n",
    "        return pd.Series([None, None, None, None])\n",
    "    \n",
    "    addr = str(address).strip().replace('\"', '').replace(\"'\", \"\")\n",
    "    \n",
    "    # Extract postal code using Canadian postal code pattern\n",
    "    postal_code_pattern = r'([A-Za-z]\\d[A-Za-z][ -]?\\d[A-Za-z]\\d)'\n",
    "    postal_code_match = re.search(postal_code_pattern, addr)\n",
    "    postal_code = postal_code_match.group(1) if postal_code_match else None\n",
    "    \n",
    "    if postal_code:\n",
    "        addr_wo_postal = addr.replace(postal_code, '').strip(', ')\n",
    "    else:\n",
    "        addr_wo_postal = addr\n",
    "    \n",
    "    # Check if address contains commas\n",
    "    if ',' in addr_wo_postal:\n",
    "        parts = [p.strip() for p in addr_wo_postal.split(',') if p.strip()]\n",
    "        \n",
    "        province = None\n",
    "        city = None\n",
    "        address_part = None\n",
    "        \n",
    "        if len(parts) >= 2:\n",
    "            province_match = re.search(r'\\b([A-Z]{2})\\b', parts[-1])\n",
    "            if province_match:\n",
    "                province = province_match.group(1)\n",
    "                city = parts[-2]\n",
    "                address_part = ', '.join(parts[:-2])\n",
    "            else:\n",
    "                city = parts[-1]\n",
    "                address_part = ', '.join(parts[:-1])\n",
    "        elif len(parts) == 1:\n",
    "            address_part = parts[0]\n",
    "        else:\n",
    "            address_part = addr_wo_postal\n",
    "    else:\n",
    "        # Space separated, try to parse from tokens\n",
    "        tokens = addr_wo_postal.split()\n",
    "        \n",
    "        province = None\n",
    "        city = None\n",
    "        address_part = None\n",
    "        \n",
    "        # Assume last token is province if it is 2 uppercase letters\n",
    "        if len(tokens) >= 2 and re.fullmatch(r'[A-Z]{2}', tokens[-1]):\n",
    "            province = tokens[-1]\n",
    "            if province == \"ON\":\n",
    "                province = \"Ontario\"\n",
    "            elif province == \"BC\":\n",
    "                province = \"British Columbia\"\n",
    "            elif province == \"AB\":\n",
    "                province = \"Alberta\"\n",
    "            elif province == \"NS\": \n",
    "                province = \"Nova Scotia\"\n",
    "            elif province == \"None\":\n",
    "                return np.nan\n",
    "            city = tokens[-2]\n",
    "            address_part = \" \".join(tokens[:-2])\n",
    "        elif len(tokens) >= 1:\n",
    "            # fallback if no province token detected\n",
    "            address_part = \" \".join(tokens[:-1])\n",
    "            city = tokens[-1]\n",
    "        else:\n",
    "            address_part = addr_wo_postal\n",
    "    \n",
    "    return pd.Series([address_part, city, province, postal_code])\n",
    "\n",
    "# Apply to normalized_df\n",
    "data[['subject.address', 'subject.city', 'subject.province', 'subject.postal_code']] = data['subject.address'].apply(standardize_and_split_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bc08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orderID', 'comps', 'subject.address', 'subject.lot_size_sf',\n",
       "       'subject.year_built', 'subject.structure_type', 'subject.roofing',\n",
       "       'subject.effective_age', 'subject.style', 'subject.basement',\n",
       "       'subject.cooling', 'subject.room_count', 'subject.num_beds',\n",
       "       'subject.gla', 'subject.subject_age', 'subject.num_baths', 'prop.id',\n",
       "       'prop.address', 'prop.bedrooms', 'prop.gla', 'prop.city',\n",
       "       'prop.province', 'prop.postal_code', 'prop.property_sub_type',\n",
       "       'prop.structure_type', 'prop.style', 'prop.levels', 'prop.room_count',\n",
       "       'prop.full_baths', 'prop.half_baths', 'prop.lot_size_sf',\n",
       "       'prop.year_built', 'prop.roof', 'prop.basement', 'prop.cooling',\n",
       "       'prop.heating', 'subject.city', 'subject.province',\n",
       "       'subject.postal_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20760a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " After parsing year_built_parsed:\n",
      "[1976. 2011. 1983. 2012. 1978. 1985. 1941. 2021. 2006. 2019. 2024. 2000.\n",
      " 1982. 2010. 2002. 1968. 1890. 1993. 2016. 1952. 2018. 2017. 1951. 2008.\n",
      " 2013. 2004. 2003. 2025. 1972. 1845. 1995. 1990. 1961. 1970. 1910. 1940.\n",
      " 1989. 1885. 1900. 1974. 2022. 2015. 1998. 1975. 2007. 1950. 1988.   nan\n",
      " 1971. 1992. 1999. 1979. 1977. 1920.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    9788.000000\n",
       "mean     1994.662648\n",
       "std        32.966353\n",
       "min      1845.000000\n",
       "25%      1979.000000\n",
       "50%      2004.000000\n",
       "75%      2017.000000\n",
       "max      2025.000000\n",
       "Name: subject.year_built_parsed, dtype: float64"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_year_built(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    value = str(value).strip().lower()\n",
    "    if value == \"new\":\n",
    "        return 2025\n",
    "    if value.isdigit():\n",
    "        return float(value)\n",
    "    if value.replace('.','',1).isdigit():\n",
    "        return float(value)\n",
    "    match = re.search(r\"([\\d.]+)\", value)\n",
    "    if not match:\n",
    "        return np.nan\n",
    "    number = float(match[0]) \n",
    "    return number\n",
    "\n",
    "data['subject.year_built_parsed'] = data['subject.year_built'].apply(parse_year_built)\n",
    "\n",
    "print(\"\\n After parsing year_built_parsed:\")\n",
    "print(data['subject.year_built_parsed'].unique())\n",
    "data['subject.year_built_parsed'].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9bed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      nan, 4.000e+01, 7.500e+01, 1.000e+01, 2.010e+03, 1.967e+03,\n",
       "       2.021e+03, 1.918e+03, 2.013e+03, 1.995e+03, 1.945e+03, 1.934e+03,\n",
       "       1.998e+03, 1.980e+03, 1.875e+03, 1.950e+03, 2.004e+03, 1.991e+03,\n",
       "       2.017e+03, 2.015e+03, 2.014e+03, 2.012e+03, 2.018e+03, 2.023e+03,\n",
       "       2.016e+03, 2.006e+03, 2.003e+03, 2.020e+03, 2.022e+03, 1.992e+03,\n",
       "       2.009e+03, 1.983e+03, 2.007e+03, 1.870e+03, 2.011e+03, 1.985e+03,\n",
       "       2.002e+03, 2.019e+03, 1.981e+03, 1.900e+03, 2.024e+03, 1.984e+03,\n",
       "       1.954e+03, 1.969e+03, 1.948e+03, 1.978e+03, 2.000e+03, 1.988e+03,\n",
       "       1.971e+03, 1.975e+03, 1.973e+03, 1.972e+03, 1.940e+03, 1.994e+03,\n",
       "       1.982e+03, 1.965e+03, 1.952e+03, 1.996e+03, 1.989e+03, 2.001e+03,\n",
       "       1.935e+03, 1.963e+03, 1.977e+03, 1.986e+03, 1.979e+03, 1.970e+03,\n",
       "       1.974e+03, 1.999e+03, 1.993e+03, 1.987e+03, 1.976e+03, 2.008e+03,\n",
       "       2.300e+01, 1.956e+03, 1.958e+03, 1.944e+03, 1.938e+03, 1.990e+03,\n",
       "       1.943e+03, 1.946e+03, 1.955e+03, 1.953e+03, 1.951e+03, 1.997e+03,\n",
       "       1.939e+03, 1.949e+03, 2.025e+03, 1.915e+03, 1.947e+03, 1.926e+03,\n",
       "       1.959e+03, 2.005e+03, 1.936e+03, 1.968e+03, 1.961e+03, 2.000e+00,\n",
       "       1.850e+03, 8.000e+00, 1.964e+03, 1.962e+03, 1.957e+03, 1.966e+03,\n",
       "       2.026e+03, 1.912e+03, 1.911e+03, 1.914e+03, 1.910e+03, 1.929e+03,\n",
       "       1.913e+03, 1.922e+03, 1.928e+03, 1.937e+03, 1.925e+03, 1.941e+03,\n",
       "       1.907e+03, 1.917e+03, 1.908e+03, 1.923e+03, 1.905e+03, 1.901e+03,\n",
       "       1.932e+03, 1.960e+03, 1.942e+03, 1.863e+03, 1.829e+03, 1.300e+01,\n",
       "       1.920e+03, 1.931e+03, 1.924e+03, 1.930e+03, 1.903e+03, 1.919e+03,\n",
       "       1.933e+03, 1.885e+03])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['prop.year_built'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129fd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " After cleaning year_built_cleaned:\n",
      "[  nan 2010. 1967. 2021. 1918. 2013. 1995. 1945. 1934. 1998. 1980. 1875.\n",
      " 1950. 2004. 1991. 2017. 2015. 2014. 2012. 2018. 2023. 2016. 2006. 2003.\n",
      " 2020. 2022. 1992. 2009. 1983. 2007. 1870. 2011. 1985. 2002. 2019. 1981.\n",
      " 1900. 2024. 1984. 1954. 1969. 1948. 1978. 2000. 1988. 1971. 1975. 1973.\n",
      " 1972. 1940. 1994. 1982. 1965. 1952. 1996. 1989. 2001. 1935. 1963. 1977.\n",
      " 1986. 1979. 1970. 1974. 1999. 1993. 1987. 1976. 2008. 1956. 1958. 1944.\n",
      " 1938. 1990. 1943. 1946. 1955. 1953. 1951. 1997. 1939. 1949. 2025. 1915.\n",
      " 1947. 1926. 1959. 2005. 1936. 1968. 1961. 1850. 1964. 1962. 1957. 1966.\n",
      " 1912. 1911. 1914. 1910. 1929. 1913. 1922. 1928. 1937. 1925. 1941. 1907.\n",
      " 1917. 1908. 1923. 1905. 1901. 1932. 1960. 1942. 1863. 1829. 1920. 1931.\n",
      " 1924. 1930. 1903. 1919. 1933. 1885.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_year_built(value):\n",
    "    try:\n",
    "        # Convert from scientific notation or string to float\n",
    "        year = float(value)\n",
    "        year = int(round(year))  # Convert to integer\n",
    "        \n",
    "        current_year = datetime.now().year\n",
    "        \n",
    "        # Handle likely invalid placeholder years (e.g., 40, 8, 13)\n",
    "        if year < 100:  \n",
    "            return np.nan\n",
    "\n",
    "        # Handle likely valid years (e.g., 1900â€“current year)\n",
    "        if 1800 <= year <= current_year:\n",
    "            return year\n",
    "        \n",
    "        return np.nan  # Drop anything else\n",
    "    except:\n",
    "        return np.nan\n",
    "data['prop.year_built_parsed'] = data['prop.year_built'].apply(clean_year_built)\n",
    "print(\"\\n After cleaning year_built_cleaned:\") \n",
    "print(data['prop.year_built_parsed'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  0.,  1.,  2.,  3.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data['prop.half_baths'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a77fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Values that counlent be parsed\n",
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "def parse_num_baths(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value.isdigit():\n",
    "        return float(value)\n",
    "    full = 0\n",
    "    half = 0\n",
    "    if ':' in value:\n",
    "        parts = value.split(':') \n",
    "        full = float(parts[0])\n",
    "        half = float(parts[1]) if len(parts) > 1 else 0\n",
    "    elif 'f' in value or 'h' in value:\n",
    "        full_match = re.search(r'(\\d+)f', value)\n",
    "        if full_match:\n",
    "            full = float(full_match.group(1))\n",
    "        half_match = re.search(r'(\\d+)h', value)\n",
    "        if half_match:\n",
    "            half = float(half_match.group(1))\n",
    "    elif 'full' in value or 'half' in value:\n",
    "        full_match = re.search(r'(\\d+)full', value)\n",
    "        if full_match:\n",
    "            full = float(full_match.group(1))\n",
    "        half_match = re.search(r'(\\d+)half', value)\n",
    "        if half_match:\n",
    "            half = float(half_match.group(1))\n",
    "    return full + (0.5 * half)\n",
    "    \n",
    "data['subject.num_baths_parsed'] = data['subject.num_baths'].apply(parse_num_baths)\n",
    "\n",
    "\n",
    "print(\"\\n Values that counlent be parsed\")\n",
    "print(data[data['subject.num_baths_parsed'].isnull()]['subject.num_baths'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41726e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_bathrooms(df, full_col='full_baths', half_col='half_baths', new_col='num_baths'):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Replace None/NaN with 0, convert to float, and compute\n",
    "    full = df[full_col].fillna(0).astype(float)\n",
    "    half = df[half_col].fillna(0).astype(float)\n",
    "    \n",
    "    df[new_col] = full + 0.5 * half\n",
    "    return df\n",
    "data = combine_bathrooms(data, full_col='prop.full_baths', half_col='prop.half_baths', new_col='prop.num_baths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d082dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1044.,   nan])"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subject.gla'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['subject.gla_parsed'] = pd.to_numeric(df['subject.gla'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a1e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 2.5, 3. , 2. , 3.5, 1. , 0.5, 4. , nan])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subject.num_baths_parsed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_room_count(value):\n",
    "    \"\"\"\n",
    "    Parse and standardize room count values such as '3', '3+1', '2+2', nan, etc.\n",
    "    Returns a float or np.nan.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip()\n",
    "    if not value:\n",
    "        return np.nan\n",
    "    # Handle values like '3+1', '2+2'\n",
    "    if '+' in value:\n",
    "        try:\n",
    "            parts = [float(x) for x in value.split('+') if x.strip().isdigit()]\n",
    "            return sum(parts)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    # Handle simple numeric values\n",
    "    try:\n",
    "        return float(value)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Example usage:\n",
    "data['subject.num_beds_parsed'] = data['subject.num_beds'].apply(parse_room_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_lot_size_sf(lot_size):\n",
    "    if pd.isna(lot_size):\n",
    "        return np.nan\n",
    "    lot_size = lot_size.lower().strip()\n",
    "    if any(x in lot_size.lower() for x in ['n/a','na','nan']):\n",
    "        return np.nan\n",
    "    value = lot_size.replace('+/-','')\n",
    "    match = re.search(r\"([\\d.]+)\", value)\n",
    "    if not match:\n",
    "        return np.nan\n",
    "    number = float(match[0])\n",
    "    if any(x in value for x in ['acres', 'acre','ac']):\n",
    "        return number * 43560\n",
    "    elif any(x in value for x in ['sqm','sq m']):\n",
    "        return number * 10.7639\n",
    "    elif any(x in value for x in ['sqft']):\n",
    "        return number\n",
    "    else:\n",
    "        return np.nan  \n",
    "\n",
    "data['subject.lot_size_sf_parsed'] = data['subject.lot_size_sf'].apply(parse_lot_size_sf)\n",
    "data['prop.lot_size_sf_parsed'] = data['subject.lot_size_sf'].apply(parse_lot_size_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b058b080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['subject.lot_size_sf_parsed','prop.lot_size_sf_parsed','subject.city', 'subject.province','subject.num_baths_parsed',\n",
    "       'subject.postal_code','subject.address','prop.address','prop.city','subject.gla_parsed','subject.num_beds_parsed',\n",
    "       'prop.province', 'prop.postal_code','subject.year_built_parsed','prop.year_built_parsed', 'subject.room_count','prop.room_count',\n",
    "       'prop.gla','prop.bedrooms','prop.num_baths','prop.id','orderID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f47191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (70, 3)\n",
      "y_train shape: (70, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df[[col for col in columns if col in train_df.columns]].copy()\n",
    "y_train = train_df[['orderID', 'comps']].copy()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa0694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderID</th>\n",
       "      <th>distance_to_subject</th>\n",
       "      <th>prop_type</th>\n",
       "      <th>stories</th>\n",
       "      <th>address</th>\n",
       "      <th>city_province</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>dom</th>\n",
       "      <th>location_similarity</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>age</th>\n",
       "      <th>condition</th>\n",
       "      <th>gla</th>\n",
       "      <th>room_count</th>\n",
       "      <th>bed_count</th>\n",
       "      <th>bath_count</th>\n",
       "      <th>basement_finish</th>\n",
       "      <th>parking</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4768126</td>\n",
       "      <td>0.24 KM</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>550 Paine Ave</td>\n",
       "      <td>Kanata ON K2T 0K7</td>\n",
       "      <td>Feb/21/2025</td>\n",
       "      <td>650,000</td>\n",
       "      <td>7 +/-</td>\n",
       "      <td>Similar</td>\n",
       "      <td>25x 98 / 3035.35 sf +/-</td>\n",
       "      <td>2016 +/-</td>\n",
       "      <td>Similar</td>\n",
       "      <td>1570 SqFt</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2:1</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>Sgl. Att. Gar.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4768126</td>\n",
       "      <td>0.33 KM</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>524 Paine Ave</td>\n",
       "      <td>Kanata ON K2T 0K7</td>\n",
       "      <td>Feb/27/2025</td>\n",
       "      <td>676,000</td>\n",
       "      <td>27 +/-</td>\n",
       "      <td>Similar</td>\n",
       "      <td>27 x 98 / 2664.87 sf +/-</td>\n",
       "      <td>2015 +/-</td>\n",
       "      <td>Similar</td>\n",
       "      <td>1869 SqFt</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2:1</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>Sgl. Att. Gar.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4768126</td>\n",
       "      <td>0.11 KM</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>164 Calvington Ave</td>\n",
       "      <td>Kanata ON K2T 0H8</td>\n",
       "      <td>Mar/26/2025</td>\n",
       "      <td>706,000</td>\n",
       "      <td>2 +/-</td>\n",
       "      <td>Similar</td>\n",
       "      <td>22 x 89 / 3159.74 sf +/-</td>\n",
       "      <td>2013 +/-</td>\n",
       "      <td>Similar</td>\n",
       "      <td>1830 SqFt</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2:1</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>Sgl. Att. Gar.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4777578</td>\n",
       "      <td>0.68 KM</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>565 Boulder Creek Cir</td>\n",
       "      <td>Langdon AB T0J 1X3</td>\n",
       "      <td>Mar/28/2025</td>\n",
       "      <td>826,000</td>\n",
       "      <td>42</td>\n",
       "      <td>Similar</td>\n",
       "      <td>7840 SqFt</td>\n",
       "      <td>17</td>\n",
       "      <td>Inferior</td>\n",
       "      <td>2342 SqFt</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2:1</td>\n",
       "      <td>Unfinished/Walkout</td>\n",
       "      <td>Quad or More Attached</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4777578</td>\n",
       "      <td>0.38 KM</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2 Storey</td>\n",
       "      <td>264 Boulder Creek Dr</td>\n",
       "      <td>Langdon AB T0J 1X3</td>\n",
       "      <td>Apr/25/2025</td>\n",
       "      <td>930,000</td>\n",
       "      <td>18</td>\n",
       "      <td>Inferior</td>\n",
       "      <td>8276 SqFt</td>\n",
       "      <td>11</td>\n",
       "      <td>Similar</td>\n",
       "      <td>2700 SqFt</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3:1</td>\n",
       "      <td>Full/Finished</td>\n",
       "      <td>Quad or More Attached</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orderID distance_to_subject  prop_type   stories                address  \\\n",
       "0  4768126             0.24 KM  Townhouse  2 Storey          550 Paine Ave   \n",
       "1  4768126             0.33 KM  Townhouse  2 Storey          524 Paine Ave   \n",
       "2  4768126             0.11 KM  Townhouse  2 Storey     164 Calvington Ave   \n",
       "3  4777578             0.68 KM   Detached  2 Storey  565 Boulder Creek Cir   \n",
       "4  4777578             0.38 KM   Detached  2 Storey   264 Boulder Creek Dr   \n",
       "\n",
       "        city_province    sale_date sale_price     dom location_similarity  \\\n",
       "0   Kanata ON K2T 0K7  Feb/21/2025    650,000   7 +/-             Similar   \n",
       "1   Kanata ON K2T 0K7  Feb/27/2025    676,000  27 +/-             Similar   \n",
       "2   Kanata ON K2T 0H8  Mar/26/2025    706,000   2 +/-             Similar   \n",
       "3  Langdon AB T0J 1X3  Mar/28/2025    826,000      42             Similar   \n",
       "4  Langdon AB T0J 1X3  Apr/25/2025    930,000      18            Inferior   \n",
       "\n",
       "                   lot_size       age condition        gla room_count  \\\n",
       "0   25x 98 / 3035.35 sf +/-  2016 +/-   Similar  1570 SqFt          6   \n",
       "1  27 x 98 / 2664.87 sf +/-  2015 +/-   Similar  1869 SqFt          8   \n",
       "2  22 x 89 / 3159.74 sf +/-  2013 +/-   Similar  1830 SqFt          7   \n",
       "3                 7840 SqFt        17  Inferior  2342 SqFt          8   \n",
       "4                 8276 SqFt        11   Similar  2700 SqFt          8   \n",
       "\n",
       "  bed_count bath_count     basement_finish                parking neighborhood  \n",
       "0         3        2:1       Full/Finished         Sgl. Att. Gar.               \n",
       "1         5        2:1       Full/Finished         Sgl. Att. Gar.               \n",
       "2         4        2:1       Full/Finished         Sgl. Att. Gar.               \n",
       "3         3        2:1  Unfinished/Walkout  Quad or More Attached               \n",
       "4         3        3:1       Full/Finished  Quad or More Attached               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "comps = y_train.copy()\n",
    "records = []\n",
    "for _, row in comps.iterrows():\n",
    "    orderID = row['orderID']\n",
    "    prop_list = row['comps']\n",
    "    prop_list = ast.literal_eval(prop_list)\n",
    "    if isinstance(prop_list, str):\n",
    "        try:\n",
    "            prop_list = json.loads(prop_list.replace(\"'\", '\"'))\n",
    "        except Exception as e:\n",
    "            # print(f\"Skipping row with orderID {orderID} due to JSON error: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not isinstance(prop_list, list):\n",
    "        continue\n",
    "    for prop in prop_list:\n",
    "    \n",
    "        prop_record = {\n",
    "            \"orderID\": orderID,\n",
    "            \"distance_to_subject\": prop.get('distance_to_subject', None),\n",
    "          \"prop_type\": prop.get('prop_type', None),\n",
    "          \"stories\": prop.get('stories', None),\n",
    "          \"address\": prop.get('address', None),\n",
    "          \"city_province\": prop.get('city_province', None),\n",
    "          \"sale_date\": prop.get('sale_date', None),\n",
    "          \"sale_price\": prop.get('sale_price', None),\n",
    "          \"dom\": prop.get('dom', None),\n",
    "          \"location_similarity\":prop.get('location_similarity', None),\n",
    "          \"lot_size\": prop.get('lot_size', None),\n",
    "          \"age\":  prop.get('age', None),\n",
    "          \"condition\": prop.get('condition', None), \n",
    "          \"gla\": prop.get('gla', None),\n",
    "          \"room_count\": prop.get('room_count', None),\n",
    "          \"bed_count\":  prop.get('bed_count', None),\n",
    "          \"bath_count\": prop.get('bath_count', None),\n",
    "          \"basement_finish\": prop.get('basement_finish', None),\n",
    "          \"parking\": prop.get('parking', None),\n",
    "          \"neighborhood\": prop.get('neighborhood', None)\n",
    "        }\n",
    "        records.append(prop_record)\n",
    "\n",
    "comps_df = pd.DataFrame(records)\n",
    "display(comps_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ee547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\pranj\\miniconda3\\envs\\cpsc330\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pranj\\miniconda3\\envs\\cpsc330\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\pranj\\miniconda3\\envs\\cpsc330\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7372e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['subject.lot_size_sf_parsed', 'prop.lot_size_sf_parsed', 'subject.city', 'subject.province', 'subject.num_baths_parsed', 'subject.postal_code', 'prop.address', 'prop.city', 'subject.gla_parsed', 'subject.num_beds_parsed', 'prop.province', 'prop.postal_code', 'subject.year_built_parsed', 'prop.year_built_parsed', 'prop.room_count', 'prop.gla', 'prop.bedrooms', 'prop.num_baths', 'prop.id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[349], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject.address\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop.address\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject.postal_code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop.postal_code\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Identify numeric and categorical columns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pranj\\miniconda3\\envs\\cpsc330\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\pranj\\miniconda3\\envs\\cpsc330\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pranj\\miniconda3\\envs\\cpsc330\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['subject.lot_size_sf_parsed', 'prop.lot_size_sf_parsed', 'subject.city', 'subject.province', 'subject.num_baths_parsed', 'subject.postal_code', 'prop.address', 'prop.city', 'subject.gla_parsed', 'subject.num_beds_parsed', 'prop.province', 'prop.postal_code', 'subject.year_built_parsed', 'prop.year_built_parsed', 'prop.room_count', 'prop.gla', 'prop.bedrooms', 'prop.num_baths', 'prop.id'] not in index\""
     ]
    }
   ],
   "source": [
    "df = train_df[columns].copy()\n",
    "\n",
    "df = df.drop(columns=['subject.address', 'prop.address', 'subject.postal_code', 'prop.postal_code'])\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "num_cols = [col for col in df.columns if any(key in col for key in ['lot_size', 'gla', 'num_baths', 'room_count', 'year_built', 'num_beds', 'bedrooms'])]\n",
    "cat_cols = list(set(df.columns) - set(num_cols) - {'order.id', 'prop.id'})\n",
    "\n",
    "# Create preprocessing pipeline for numeric and categorical separately\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_cols),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), cat_cols)\n",
    "    ]\n",
    ")\n",
    "X_preprocessed = preprocessor.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kneed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b82eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_cols = [col for col in df.columns if col.startswith('subject.')]\n",
    "prop_cols = [col for col in df.columns if col.startswith('prop.') and col not in ['prop.id']]\n",
    "\n",
    "# Get corresponding indices\n",
    "subject_indices = [i for i, col in enumerate(df.columns) if col in subject_cols]\n",
    "prop_indices = [i for i, col in enumerate(df.columns) if col in prop_cols]\n",
    "\n",
    "# Slice preprocessed features into subject and prop parts\n",
    "subject_feats = X_preprocessed[:, subject_indices]\n",
    "prop_feats = X_preprocessed[:, prop_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdcd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(subject_feats, prop_feats)\n",
    "\n",
    "# Get top 3 most similar comp indices for each subject\n",
    "top_3_indices = np.argsort(similarity, axis=1)[:, -3:][:, ::-1]  # top 3, in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_ids = df['prop.id'].values\n",
    "top_3_prop_ids = np.array([[prop_ids[j] for j in row] for row in top_3_indices])\n",
    "\n",
    "# Build final result dataframe\n",
    "results_df = df[['orderID']].copy()\n",
    "results_df['comp_1_prop_id'] = top_3_prop_ids[:, 0]\n",
    "results_df['comp_2_prop_id'] = top_3_prop_ids[:, 1]\n",
    "results_df['comp_3_prop_id'] = top_3_prop_ids[:, 2]\n",
    "\n",
    "results_df = results_df.drop_duplicates(subset=['orderID'])\n",
    "\n",
    "# Show result\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73eea60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
